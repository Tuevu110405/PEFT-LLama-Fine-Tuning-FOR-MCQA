# PEFT-LLama-Fine-Tuning-FOR-MCQA

In this project, I mainly aim to learn how to use unsloth for PEFT fine-tuning, so due to limited resources, the performance is not good.

You can find the model at [Llama-3.2-1B-bnb-4bit-MedMCQA](https://huggingface.co/tientuevu/Llama-3.2-1B-bnb-4bit-MedMCQA). At the end Project_PEFT_Llama_Mcqa.ipynb or inference.py file, you can find how to use this model for inference on validation
